{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-15T09:20:38.983341800Z",
     "start_time": "2023-10-15T09:20:38.618421300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def find_headers(dataframe):\n",
    "    # Search Date/time header\n",
    "    header_idx = -1\n",
    "    for ri, rows in enumerate(dataframe.values):\n",
    "        for ri, row in enumerate(rows):\n",
    "            is_header = 'Date/Time'.lower() in str(row).lower()\n",
    "            if is_header:\n",
    "                header_idx = ri + 1\n",
    "                break\n",
    "\n",
    "    # Check if a valid header index was found\n",
    "    if header_idx != -1:\n",
    "        print(\"Header found at row index:\", header_idx)\n",
    "        # Set the header and skip rows accordingly\n",
    "        dataframe = pd.DataFrame(dataframe.values[header_idx:], columns=dataframe.iloc[header_idx - 1])\n",
    "        dataframe = dataframe.reset_index(drop=True)\n",
    "    else:\n",
    "        print(\"Header not found in the DataFrame\")\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def find_footer(dataframe):\n",
    "    row_index = None\n",
    "    for i, row in dataframe.iterrows():\n",
    "        if 'Station Down (D)=' in str(row['Date/Time']):\n",
    "            row_index = i\n",
    "            break\n",
    "\n",
    "    print('Remove footer at row index:', row_index)\n",
    "\n",
    "    # Remove rows from the bottom up to and including the found row\n",
    "    if row_index is not None:\n",
    "        print(\"Removing rows from index:\", row_index, -1)\n",
    "        dataframe = dataframe.iloc[:row_index]\n",
    "\n",
    "        # CLean NaN last 10 rows\n",
    "        df_no10 = dataframe.iloc[:-10]\n",
    "        df_cleaned = dataframe.tail(10).dropna(subset=['Date/Time'], how='any')\n",
    "        dataframe = pd.concat([df_no10, df_cleaned], ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        print(\"Text 'Station Down (D)=' not found\")\n",
    "\n",
    "    # Reset the index if needed\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T09:20:38.991225600Z",
     "start_time": "2023-10-15T09:20:38.982343100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T09:20:39.124262600Z",
     "start_time": "2023-10-15T09:20:38.992226800Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Work\\\\Home-2023\\\\may-project\\\\project-mei\\\\ข้อมูลย้อนหลัง10ปี\\\\ผลการตรวจวัดคุณภาพอากาศ\\\\NO2 2009-2019\\\\BanHuayking.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24460\\3862400654.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0muri\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34mr'D:\\Work\\Home-2023\\may-project\\project-mei\\ข้อมูลย้อนหลัง10ปี\\ผลการตรวจวัดคุณภาพอากาศ\\NO2 2009-2019\\BanHuayking.xlsx'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# uri = r'D:\\Work\\Home-2023\\may-project\\project-mei\\ข้อมูลย้อนหลัง10ปี\\ผลการตรวจวัดคุณภาพอากาศ\\PM10 2009-2019\\Banhuafai.xlsx'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mxls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mExcelFile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muri\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Sheet nums'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxls\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msheet_names\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, path_or_buffer, engine, storage_options)\u001B[0m\n\u001B[0;32m   1374\u001B[0m                 \u001B[0mext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"xls\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1375\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1376\u001B[1;33m                 ext = inspect_excel_format(\n\u001B[0m\u001B[0;32m   1377\u001B[0m                     \u001B[0mcontent_or_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1378\u001B[0m                 )\n",
      "\u001B[1;32mD:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001B[0m in \u001B[0;36minspect_excel_format\u001B[1;34m(content_or_path, storage_options)\u001B[0m\n\u001B[0;32m   1248\u001B[0m         \u001B[0mcontent_or_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBytesIO\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontent_or_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1249\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1250\u001B[1;33m     with get_handle(\n\u001B[0m\u001B[0;32m   1251\u001B[0m         \u001B[0mcontent_or_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"rb\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_text\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1252\u001B[0m     ) as handle:\n",
      "\u001B[1;32mD:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    793\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    794\u001B[0m             \u001B[1;31m# Binary mode\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 795\u001B[1;33m             \u001B[0mhandle\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    796\u001B[0m         \u001B[0mhandles\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    797\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:\\\\Work\\\\Home-2023\\\\may-project\\\\project-mei\\\\ข้อมูลย้อนหลัง10ปี\\\\ผลการตรวจวัดคุณภาพอากาศ\\\\NO2 2009-2019\\\\BanHuayking.xlsx'"
     ]
    }
   ],
   "source": [
    "uri = r'D:\\Work\\Home-2023\\may-project\\project-mei\\ข้อมูลย้อนหลัง10ปี\\ผลการตรวจวัดคุณภาพอากาศ\\PM10 2009-2019\\Banhuafai.xlsx'\n",
    "uri = r'D:\\Work\\Home-2023\\may-project\\project-mei\\ข้อมูลย้อนหลัง10ปี\\ผลการตรวจวัดคุณภาพอากาศ\\NO2 2009-2019\\Banhuafai.xlsx'\n",
    "uri = r'D:\\Work\\Home-2023\\may-project\\project-mei\\ข้อมูลย้อนหลัง10ปี\\ผลการตรวจวัดคุณภาพอากาศ\\NO2 2009-2019\\BanHuayking.xlsx'\n",
    "# uri = r'D:\\Work\\Home-2023\\may-project\\project-mei\\ข้อมูลย้อนหลัง10ปี\\ผลการตรวจวัดคุณภาพอากาศ\\PM10 2009-2019\\Banhuafai.xlsx'\n",
    "xls = pd.ExcelFile(uri)\n",
    "\n",
    "print('Sheet nums', xls.sheet_names)\n",
    "dfs = []\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    # Read data from the current sheet\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name,)\n",
    "    df = find_headers(df)\n",
    "    df = find_footer(df)\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "df = concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_index = None\n",
    "for i, row in df.iterrows():\n",
    "    if 'Station Down (D)=' in str(row['Date/Time']):\n",
    "        row_index = i\n",
    "        break\n",
    "\n",
    "print('Remove footer at row index:', row_index)\n",
    "\n",
    "# Remove rows from the bottom up to and including the found row\n",
    "if row_index is not None:\n",
    "    print(\"Removing rows from index:\", row_index, -1)\n",
    "    df = df.iloc[:row_index - 1]\n",
    "else:\n",
    "    print(\"Text 'Station Down (D)=' not found\")\n",
    "\n",
    "# Reset the index if needed\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str_fill = ['F', 'C', 'D', 'A', 'P', '-', 'O']\n",
    "df = df.replace(str_fill, [np.NaN] * str_fill.__len__())\n",
    "# df = df.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use a regular expression to filter columns with the pattern 'xx:xx'\n",
    "time_pattern = r'\\d{2}:\\d{2}(:\\d{2})*'\n",
    "time_columns = [col for col in df.columns if re.search(time_pattern, str(col))]\n",
    "if len(time_columns) == 24:  # Check if you have 24 time columns\n",
    "    start_time = '1990-01-01 01:00:00'\n",
    "    end_time = '1990-01-02 00:59:59'\n",
    "    time_range = pd.date_range(start=start_time, end=end_time, freq='1H')\n",
    "    time_columns = [time.strftime('%H:%M:%S') for time in time_range.time]\n",
    "else:\n",
    "    raise ValueError('The number of time columns is not 24')\n",
    "\n",
    "df = df.iloc[:,:25]\n",
    "df.columns = ['Date/Time'] + time_columns\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use melt to flatten the selected columns into rows\n",
    "melted_df = pd.melt(df, id_vars=['Date/Time'], var_name='Time', value_name='Value')\n",
    "melted_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melted_df['Datetime'] = pd.to_datetime(melted_df['Date/Time'].astype(str), format='%Y-%m-%d', errors='coerce')\n",
    "melted_df['_time_dt'] = pd.to_datetime(melted_df['Time'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "melted_df['Datetime'] += pd.to_timedelta(melted_df['_time_dt'].astype(str))\n",
    "melted_df.loc[melted_df['Time'] == '00:00:00', 'Datetime'] += pd.DateOffset(days=1)\n",
    "\n",
    "\n",
    "\n",
    "# melted_df = melted_df[['Datetime', 'Value']]\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sorted = melted_df.sort_values(by='Datetime')\n",
    "df_sorted.reset_index(drop=True, inplace=True)\n",
    "melted_df = df_sorted\n",
    "\n",
    "# Extract years from the Datetime column\n",
    "melted_df['Year'] = melted_df['Datetime'].dt.year\n",
    "unique_years = melted_df['Year'].unique()\n",
    "\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melted_df['ValueLn'] = melted_df['Value'].interpolate(method='linear')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_values = melted_df.isna().sum()\n",
    "summary_stats = melted_df.describe()\n",
    "unique_values = melted_df['Datetime'].unique()\n",
    "value_counts = melted_df['Datetime'].value_counts()\n",
    "yearly_sum = melted_df.groupby('Year').count()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearly_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df[melted_df['Value'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(melted_df['Datetime'], melted_df['Value'], linestyle='-', lw=0.5)\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series Plot')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot seasonality for each year\n",
    "plt.figure(figsize=(360, 12))\n",
    "# First subplot on the left\n",
    "\n",
    "for year in unique_years:\n",
    "    year_data = melted_df[melted_df['Year'] == year]\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(year_data['Datetime'], year_data['ValueLn'], label=f'Year {year}', lw=0.5)\n",
    "    plt.ylabel('Value')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(year_data['Datetime'], year_data['Value'], label=f'Year {year}', lw=0.5)\n",
    "    plt.ylabel('Value')\n",
    "\n",
    "plt.xlabel('Datetime')\n",
    "\n",
    "plt.title('Seasonality Plot for Each Year')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('Seasonality.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
