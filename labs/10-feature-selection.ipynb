{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ValueLn_BP', 'ValueLn_DEV', 'ValueLn_NO2', 'ValueLn_PM10', 'ValueLn_RAIN', 'ValueLn_RH', 'ValueLn_SO2_1', 'ValueLn_SW', 'ValueLn_TEMP', 'ValueLn_TSP', 'ValueLn_WD', 'ValueLn_WS']\n",
      "0\n",
      "['ValueLn_NO2', 'ValueLn_PM10', 'ValueLn_RH', 'ValueLn_TEMP', 'ValueLn_TSP']\n",
      "[9.66982510e-020 2.00907342e-088 0.00000000e+000 1.53127705e-203\n",
      " 1.42194828e-006 0.00000000e+000 1.00000000e+000 3.41226041e-070\n",
      " 2.33401512e-262 2.83304013e-186 5.05810931e-079 3.41226041e-070]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "file_path = 'D:\\\\Work\\\\Home-2023\\\\may-project\\\\labs\\\\outputsx\\\\merged\\\\merged_บ้านสบป้าด.csv.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'Datetime' to datetime object\n",
    "data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "\n",
    "# Optionally, extract more time-related features (e.g., hour, weekday) if needed\n",
    "# data['Hour'] = data['Datetime'].dt.hour\n",
    "# data['Weekday'] = data['Datetime'].dt.weekday\n",
    "\n",
    "# Select columns that start with \"ValueLn\", excluding 'ValueLn_SO2'\n",
    "selected_columns = [col for col in data.columns if col.startswith(\"ValueLn\") and col != 'ValueLn_SO2']\n",
    "features_data = data[selected_columns]\n",
    "\n",
    "print(selected_columns  )\n",
    "\n",
    "# Handling missing values\n",
    "features_data = features_data.fillna(features_data.median())\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(features_data)\n",
    "\n",
    "# Define the target variable\n",
    "y = data['ValueLn_SO2']\n",
    "y = y.fillna(y.median())\n",
    "\n",
    "print(y.isnull().sum())\n",
    "\n",
    "\n",
    "# Feature Selection\n",
    "k = 5  # Number of top features to select\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "X_new = selector.fit_transform(scaled_data, y)\n",
    "\n",
    "# Splitting the dataset for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train and X_test now contain the selected features for your LSTM model\n",
    "print(list(features_data.columns[list(selector.get_support(indices=True))]))\n",
    "print(selector.pvalues_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17532, 5) (17532,)\n",
      "[0.01587302 0.04241071 0.92929293 0.39086409 0.03552398] (17532,)\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 5, 5), dtype=tf.float32, name='lstm_8_input'), name='lstm_8_input', description=\"created by layer 'lstm_8_input'\"), but it was called on an input with incompatible shape (None, 5).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_11\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"lstm_8\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 5)\n    \n    Call arguments received by layer \"sequential_11\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 5), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Work\\Home-2023\\may-project\\labs\\10-feature-selection.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Home-2023/may-project/labs/10-feature-selection.ipynb#W1sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Home-2023/may-project/labs/10-feature-selection.ipynb#W1sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Work/Home-2023/may-project/labs/10-feature-selection.ipynb#W1sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m7200\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Home-2023/may-project/labs/10-feature-selection.ipynb#W1sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Home-2023/may-project/labs/10-feature-selection.ipynb#W1sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m mse \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\KANDAT~1\\AppData\\Local\\Temp\\__autograph_generated_filedpa8dk9x.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Users\\kandation\\me\\anaconda3\\envs\\project-may\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_11\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"lstm_8\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 5)\n    \n    Call arguments received by layer \"sequential_11\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 5), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.feature_selection import SelectKBest, SequentialFeatureSelector, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "# GPU configuration (optional, for fine-tuning performance)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Load the data\n",
    "file_path = 'D:\\\\Work\\\\Home-2023\\\\may-project\\\\labs\\\\outputsx\\\\merged\\\\merged_บ้านสบป้าด.csv.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'Datetime' to datetime object\n",
    "data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "\n",
    "# Select columns that start with \"ValueLn\", excluding 'ValueLn_SO2'\n",
    "selected_columns = [col for col in data.columns if col.startswith(\"ValueLn\") and col != 'ValueLn_SO2']\n",
    "features_data = data[selected_columns]\n",
    "\n",
    "# Handling missing values\n",
    "features_data = features_data.fillna(features_data.median())\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(features_data)\n",
    "\n",
    "# Define the target variable\n",
    "y = data['ValueLn_SO2']\n",
    "y = y.fillna(y.median())\n",
    "\n",
    "# Feature Selection\n",
    "k = 5  # Number of top features to select\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "X_new = selector.fit_transform(scaled_data, y)\n",
    "\n",
    "# TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(X_new):\n",
    "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_train[0], y_train.shape)\n",
    "\n",
    "    # Here, you can add your model training and evaluation code\n",
    "    # For example:\n",
    "    # model.fit(X_train, y_train)\n",
    "    # Evaluate the model on X_test, y_test\n",
    "\n",
    "# Note: The exact way you train and evaluate your model may vary depending on the model you are using\n",
    "\n",
    "\n",
    "    # Build your LSTM model\n",
    "\n",
    "# Rest of your model code\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(50, input_shape=(X_train.shape[1], 5), activation='relu', recurrent_activation='sigmoid', return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', recurrent_activation='sigmoid'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=7200, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'MSE for fold: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170\n",
      " 180 190]\n",
      "--------------------------------------------------\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "[  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170\n",
      " 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350]\n",
      "--------------------------------------------------\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51]\n",
      "[  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170\n",
      " 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350\n",
      " 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510]\n",
      "--------------------------------------------------\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67]\n",
      "[  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170\n",
      " 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350\n",
      " 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530\n",
      " 540 550 560 570 580 590 600 610 620 630 640 650 660 670]\n",
      "--------------------------------------------------\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "[  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170\n",
      " 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350\n",
      " 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530\n",
      " 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 710\n",
      " 720 730 740 750 760 770 780 790 800 810 820 830]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-may",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
